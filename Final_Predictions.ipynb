{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ff49c214119f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepeatVector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "# import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.layers import Dense, Convolution2D, Dropout, LSTM,Input, TimeDistributed, Embedding, Add, Activation, RepeatVector\n",
    "from keras.models import Sequential, Model\n",
    "# from keras.optimizers import Adam\n",
    "from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./indices_2_words.p','rb') as f1:\n",
    "    indices_2_words = pickle.load(f1)\n",
    "\n",
    "with open('./word_2_indices.p','rb') as f2:\n",
    "    words_2_indices = pickle.load(f2)\n",
    "\n",
    "f1.close()\n",
    "f2.close()\n",
    "vocab_size = len(indices_2_words)\n",
    "print(len(indices_2_words))\n",
    "print(len(words_2_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indices_2_words[456])\n",
    "print(words_2_indices['backpacker'])\n",
    "max_len= 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "max_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model_inp = Input(shape=(2048,))\n",
    "image_model_ly1 = Dense(embedding_size, activation='relu')(image_model_inp)\n",
    "image_model_ly2 = RepeatVector(max_len)(image_model_ly1)\n",
    "\n",
    "image_model = Model(input =image_model_inp,output = image_model_ly2)\n",
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model_inp = Input(shape=(max_len,))\n",
    "language_model_ly1 = Embedding(input_dim=vocab_size, output_dim=embedding_size)(language_model_inp)\n",
    "language_model_ly2 = LSTM(256, return_sequences=True)(language_model_ly1)\n",
    "language_model_ly3 = TimeDistributed(Dense(embedding_size))(language_model_ly2)\n",
    "\n",
    "language_model = Model(input=language_model_inp,output=language_model_ly3)\n",
    "language_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ly1 = Add()([image_model_ly2, language_model_ly3])\n",
    "model_ly2 = LSTM(128, return_sequences=True)(model_ly1)\n",
    "model_ly3 = LSTM(512, return_sequences=False)(model_ly2)\n",
    "model_ly4 = Dense(vocab_size,activation = 'softmax')(model_ly3)\n",
    "\n",
    "\n",
    "new_model = Model(input = [image_model_inp,language_model_inp],output = model_ly4)\n",
    "new_model.load_weights(\"./model_weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_preprocessing(img_path):\n",
    "    img = image.load_img(img_path,target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img_emb = model.predict(img).reshape(2048)\n",
    "#     print(type(img_emb))\n",
    "    return img_emb   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../../project/Flickr8k_Dataset/Flicker8k_Dataset/1386251841_5f384a0fea.jpg\"\n",
    "test_img = Image_preprocessing(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_captions(image):\n",
    "    start_word = [\"<start>\"]\n",
    "    while True:\n",
    "        par_caps = [words_2_indices[i] for i in start_word]\n",
    "        par_caps = sequence.pad_sequences([par_caps], maxlen=max_len, padding='post')\n",
    "        preds = new_model.predict([np.array([image]), np.array(par_caps)])\n",
    "        word_pred = indices_2_words[np.argmax(preds[0])]\n",
    "        start_word.append(word_pred)\n",
    "        \n",
    "        if word_pred == \"<end>\" or len(start_word) > max_len:\n",
    "            break\n",
    "            \n",
    "    return ' '.join(start_word[1:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Image(filename=img_path)\n",
    "display(z)\n",
    "\n",
    "print (predict_captions(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
